{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch  as th\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import gzip as gz\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoConfig\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from BESTRq_classes.BESTRq import BestRqFramework, RandomProjectionQuantizer\n",
    "from compute_fft import compute_spectrogram, plot_spectrogram, mask_and_replace\n",
    "from models.CNN_BiLSTM_Attention import ParallelModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN implementation : comparison between spectrum and temporal serie \n",
    "https://towardsdatascience.com/synthetic-time-series-data-a-gan-approach-869a984f2239"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_net(model, n_layers, hidden_units, output_units):\n",
    "    for i in range(n_layers):\n",
    "        model.add_module(f'GRU_{i + 1}', nn.GRU(hidden_units, hidden_units, batch_first=True))\n",
    "        model.add_module('OUT', nn.Sequential(nn.Linear(hidden_units, output_units), nn.Sigmoid()))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Supervisor(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Supervisor, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.model = self.build()\n",
    "\n",
    "    def build(self):\n",
    "        model = nn.Sequential()\n",
    "        return make_net(model,\n",
    "                        n_layers=2,\n",
    "                        hidden_units=self.hidden_dim,\n",
    "                        output_units=self.hidden_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, hidden_dim, net_type='GRU'):\n",
    "        super(Generator, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.net_type = net_type\n",
    "        self.model = self.build()\n",
    "\n",
    "    def build(self):\n",
    "        layers = []\n",
    "        if self.net_type == 'GRU':\n",
    "            layers.append(nn.GRU(input_size=self.hidden_dim, hidden_size=self.hidden_dim, num_layers=3, batch_first=True))\n",
    "        else:\n",
    "            # Autre type de réseau de neurones récurrent\n",
    "            pass\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, hidden_dim, net_type='GRU'):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.net_type = net_type\n",
    "        self.model = self.build()\n",
    "\n",
    "    def build(self):\n",
    "        layers = []\n",
    "        if self.net_type == 'GRU':\n",
    "            layers.append(nn.GRU(input_size=self.hidden_dim, hidden_size=self.hidden_dim, num_layers=3, batch_first=True))\n",
    "        else:\n",
    "            # Autre type de réseau de neurones récurrent\n",
    "            pass\n",
    "        layers.append(nn.Linear(self.hidden_dim, 1))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return th.sigmoid(self.model(x))\n",
    "\n",
    "class Recovery(nn.Module):\n",
    "    def __init__(self, hidden_dim, n_seq):\n",
    "        super(Recovery, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_seq = n_seq\n",
    "        self.model = self.build()\n",
    "\n",
    "    def build(self):\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(self.hidden_dim, self.hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(self.hidden_dim, self.n_seq))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Embedder(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Embedder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.model = self.build()\n",
    "\n",
    "    def build(self):\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(self.hidden_dim, self.hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(self.hidden_dim, self.hidden_dim))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Supervisor(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Supervisor, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.model = self.build()\n",
    "\n",
    "    def build(self):\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(self.hidden_dim, self.hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(self.hidden_dim, self.hidden_dim))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 128])\n"
     ]
    }
   ],
   "source": [
    "# Définition des dimensions\n",
    "latent_dim = 128  # Dimension de l'espace latent\n",
    "input_dim = 28*28  # Dimension des données d'entrée, par exemple pour des images MNIST\n",
    "\n",
    "# Initialisation du GAN\n",
    "generator = Generator(hidden_dim=128)\n",
    "discriminator = Discriminator(hidden_dim=128)\n",
    "supervisor = Supervisor(hidden_dim=128)\n",
    "\n",
    "# Entraînement du GAN (à implémenter)\n",
    "# Vous devrez définir la fonction d'entraînement du GAN en alternant entre\n",
    "# l'entraînement du générateur, du discriminateur et du superviseur.\n",
    "\n",
    "# Génération de données\n",
    "def generate_data(n_samples):\n",
    "    # Génération de vecteurs aléatoires dans l'espace latent\n",
    "    noise = th.randn(n_samples, latent_dim)\n",
    "    # Utilisation du générateur pour générer de nouvelles données\n",
    "    generated_data = generator(noise)\n",
    "    return generated_data\n",
    "\n",
    "# Génération de 10 exemples de données\n",
    "generated_samples = generate_data(10)\n",
    "print(generated_samples[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
