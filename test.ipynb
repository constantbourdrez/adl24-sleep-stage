{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch as th\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertGenerationConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 2,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 1024,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 4096,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert-generation\",\n",
       "  \"num_attention_heads\": 16,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.38.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50358\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = transformers.BertGenerationConfig()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if th.cuda.is_available() else \"cpu\"\n",
    "print(f\"Use device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = th.device('cpu')\n",
    "x = th.rand((10000, 10000), dtype=th.float32)\n",
    "y = th.rand((10000, 10000), dtype=th.float32)\n",
    "x = x.to(device)\n",
    "y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1850, 0.1728, 0.0564,  ..., 0.3192, 0.9514, 0.2227],\n",
       "        [0.2243, 0.6131, 0.0697,  ..., 0.0159, 0.0100, 0.1830],\n",
       "        [0.2376, 0.0264, 0.1001,  ..., 0.3630, 0.3957, 0.1977],\n",
       "        ...,\n",
       "        [0.4425, 0.0247, 0.0834,  ..., 0.0238, 0.3545, 0.0566],\n",
       "        [0.3793, 0.3825, 0.7382,  ..., 0.7046, 0.0879, 0.4709],\n",
       "        [0.2573, 0.6845, 0.1712,  ..., 0.5605, 0.3641, 0.2750]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = th.device('mps')\n",
    "x = th.rand((10000, 10000), dtype=th.float32)\n",
    "y = th.rand((10000, 10000), dtype=th.float32)\n",
    "x = x.to(device)\n",
    "y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2557, 0.3103, 0.0802,  ..., 0.0025, 0.1610, 0.2204],\n",
       "        [0.0038, 0.1113, 0.0733,  ..., 0.0086, 0.1609, 0.1734],\n",
       "        [0.1805, 0.0270, 0.2928,  ..., 0.2096, 0.0815, 0.1382],\n",
       "        ...,\n",
       "        [0.5709, 0.5700, 0.3107,  ..., 0.7539, 0.1653, 0.4005],\n",
       "        [0.0097, 0.3807, 0.2067,  ..., 0.3045, 0.5589, 0.0166],\n",
       "        [0.3125, 0.2030, 0.4086,  ..., 0.3201, 0.2113, 0.1653]],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch backend MPS is available? True\n",
      "current PyTorch installation built with MPS activated? True\n",
      "check the torch MPS backend: mps\n",
      "test torch tensor on MPS: tensor([1, 2, 3], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(f\"torch backend MPS is available? {th.backends.mps.is_available()}\")\n",
    "print(f\"current PyTorch installation built with MPS activated? {th.backends.mps.is_built()}\")\n",
    "print(f\"check the torch MPS backend: {th.device('mps')}\")\n",
    "print(f\"test torch tensor on MPS: {th.tensor([1,2,3], device='mps')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-sleep-project-wfnrCJ-y-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
